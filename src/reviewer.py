# src/reviewer.py
import os
import json
import logging
import sqlite3
import pandas as pd
import numpy as np
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, List
from collections import defaultdict

# --- í”„ë¡œì íŠ¸ ê³µí†µ ìœ í‹¸ë¦¬í‹° ë° ëª¨ë“ˆ ì„í¬íŠ¸ ---
from utils import (
    setup_logging,
    load_config,
    OUTPUT_DIR,
    KST
)
from notifier import send_discord_message, is_valid_webhook

# --- ë¡œê¹… ì„¤ì • ---
setup_logging()
logger = logging.getLogger("Reviewer")

# --- ìƒìˆ˜ ì •ì˜ ---
DB_PATH = OUTPUT_DIR / "trading_log.db"
REVIEW_LOG_PATH = OUTPUT_DIR / "review_log.json"
CONFIG_PATH = Path("/app/config/config.json")  # ì„¤ì • íŒŒì¼ ê²½ë¡œ ëª…ì‹œ
ANALYSIS_CSV_PATH = OUTPUT_DIR / "completed_trades_analysis.csv"

# --- ìë™ íŠœë‹ì„ ìœ„í•œ ì•ˆì „ì¥ì¹˜ ë° ìƒìˆ˜ ì •ì˜ ---
MIN_STOP_LOSS_PCT = 0.015   # ì†ì ˆ í•˜í•œ(1.5%)
MAX_TAKE_PROFIT_PCT = 0.50  # ìµì ˆ ìƒí•œ(50%)
CONSECUTIVE_FAILURES_THRESHOLD = 3  # ì—°ì† ë¶€ì§„ ì„ê³„


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Webhook ë¡œë”©: config.json(notifier.discord_webhook) â†’ ENV(DISCORD_WEBHOOK_URL)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_webhook_url() -> str:
    try:
        cfg = load_config()
        webhook = (
            cfg.get("notifier", {}).get("discord_webhook")
            or os.getenv("DISCORD_WEBHOOK_URL", "").strip()
        )
        return webhook or ""
    except Exception as e:
        logger.warning(f"ì›¹í›… URL ë¡œë“œ ì¤‘ ì˜ˆì™¸(ë¬´ì‹œ): {e}")
        return ""


WEBHOOK_URL = _load_webhook_url()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¦¬ë·° ë¡œê·¸ I/O
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_last_review_info() -> dict:
    """ë§ˆì§€ë§‰ ë¦¬ë·° ê¸°ë¡(ID, ë‚ ì§œ, ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜)ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not REVIEW_LOG_PATH.exists():
        return {"last_trade_id": 0, "consecutive_failures": 0}
    try:
        with open(REVIEW_LOG_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if "consecutive_failures" not in data:
                data["consecutive_failures"] = 0
            if "last_trade_id" not in data:
                data["last_trade_id"] = 0
            return data
    except (json.JSONDecodeError, IOError) as e:
        logger.warning(f"ë¦¬ë·° ë¡œê·¸ íŒŒì‹± ì‹¤íŒ¨(ì´ˆê¸°í™”): {e}")
        return {"last_trade_id": 0, "consecutive_failures": 0}


def update_review_log(last_trade_id: int, consecutive_failures: int):
    """ë¦¬ë·° ë¡œê·¸ë¥¼ ìµœì‹  ì •ë³´ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    log_data = {
        "last_trade_id": int(last_trade_id),
        "last_review_date": datetime.now(KST).isoformat(),
        "consecutive_failures": int(consecutive_failures)
    }
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    with open(REVIEW_LOG_PATH, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)
    logger.info(
        f"[ë¦¬ë·° ë¡œê·¸ ì—…ë°ì´íŠ¸] last_trade_id={log_data['last_trade_id']}, "
        f"consecutive_failures={log_data['consecutive_failures']} "
        f"({log_data['last_review_date']})"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ë¡œë“œ: ë¯¸ê²€í†  ê±°ë˜ ê°€ì ¸ì˜¤ê¸°(ì¼ë°˜í™”, ì•ˆì „í•œ ì •ê·œí™”/ê²€ì¦ í¬í•¨)
# trades ìŠ¤í‚¤ë§ˆ ê°€ì • ì»¬ëŸ¼(ê°€ê¸‰ì ):
#   id, timestamp, ticker, name?, side('buy'|'sell'), qty, price,
#   pnl_amount?, sell_reason?, gpt_score?, gpt_analysis?, strategy_name?, parent_trade_id?
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_new_trades(last_trade_id: int) -> pd.DataFrame:
    if not DB_PATH.exists():
        logger.warning(f"ê±°ë˜ DB ë¯¸ì¡´ì¬: {DB_PATH}")
        return pd.DataFrame()

    with sqlite3.connect(DB_PATH) as conn:
        query = "SELECT * FROM trades WHERE id > ? ORDER BY timestamp ASC"
        df = pd.read_sql_query(query, conn, params=[int(last_trade_id)], parse_dates=['timestamp'])

    if df.empty:
        logger.info("ìƒˆë¡œìš´ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return df

    # íƒ€ì… ì •ê·œí™”
    for col in ['qty', 'price', 'pnl_amount', 'id', 'parent_trade_id', 'gpt_score']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # side/ticker/name ì •ê·œí™”
    if 'side' in df.columns:
        df['side'] = df['side'].astype(str).str.lower().str.strip()
    if 'ticker' in df.columns:
        df['ticker'] = df['ticker'].astype(str).str.strip()
    if 'name' in df.columns:
        df['name'] = df['name'].astype(str).str.strip()

    # í•„ìˆ˜ í•„ë“œ ì²´í¬
    required_cols = {'id', 'timestamp', 'ticker', 'side', 'qty', 'price'}
    missing = required_cols - set(df.columns)
    if missing:
        logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        return pd.DataFrame()

    # ê²°ì¸¡/ì´ìƒì¹˜ ì œê±°
    before = len(df)
    df = df.dropna(subset=list(required_cols))
    df = df[(df['qty'] > 0) & (df['price'] > 0)]
    after = len(df)
    if after < before:
        logger.info(f"ì •ê·œí™”ì—ì„œ {before - after}ê±´ í•„í„°ë§ë¨(ê²°ì¸¡/ìŒìˆ˜ ì œê±°).")

    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FIFO ë§¤ì¹­: ë§¤ë„ë³„ ì‹¤í˜„ì†ìµ ì¬ê³„ì‚°
# ë°˜í™˜ ì»¬ëŸ¼: sell_id, profit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def match_trades_fifo(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame(columns=['sell_id', 'profit'])

    buys = df[df['side'] == 'buy'].sort_values('timestamp').copy()
    sells = df[df['side'] == 'sell'].sort_values('timestamp').copy()

    if buys.empty or sells.empty:
        logger.info("ë§¤ìˆ˜/ë§¤ë„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë§¤ì¹­ ë¶ˆê°€.")
        return pd.DataFrame(columns=['sell_id', 'profit'])

    buys['qty_remaining'] = buys['qty']
    completed = []

    for _, sell in sells.iterrows():
        sell_qty_needed = float(sell['qty'])
        potential_buys = buys[
            (buys['ticker'] == sell['ticker']) &
            (buys['timestamp'] < sell['timestamp']) &
            (buys['qty_remaining'] > 0)
        ].sort_values('timestamp')

        for buy_idx, buy in potential_buys.iterrows():
            if sell_qty_needed <= 0:
                break
            match_qty = float(min(sell_qty_needed, buy['qty_remaining']))
            profit = (float(sell['price']) - float(buy['price'])) * match_qty

            completed.append({
                'sell_id': int(sell['id']),
                'profit': float(profit),
                # ì•„ë˜ ê°’ë“¤ì€ CSV/ë¶„ì„ í™•ì¥ì„ ìœ„í•œ íŒíŠ¸
                'sell_t': sell['timestamp'],
                'sell_price': float(sell['price']),
                'sell_qty': float(sell['qty']),
                'sell_ticker': sell['ticker'],
                'sell_name': str(sell['name']) if 'name' in sell else None,
                'sell_reason': str(sell['sell_reason']) if 'sell_reason' in sell else None,
                'buy_id': int(buy['id']),
                'buy_t': buy['timestamp'],
                'buy_price': float(buy['price']),
                'buy_qty': float(match_qty),
                'buy_strategy': str(buy['strategy_name']) if 'strategy_name' in buy else None,
                'buy_gpt_score': float(buy['gpt_score']) if 'gpt_score' in buy and pd.notna(buy['gpt_score']) else None,
                'buy_gpt_analysis': buy['gpt_analysis'] if 'gpt_analysis' in buy else None,
            })

            sell_qty_needed -= match_qty
            buys.at[buy_idx, 'qty_remaining'] = float(buy['qty_remaining'] - match_qty)

    if not completed:
        return pd.DataFrame(columns=['sell_id', 'profit'])

    return pd.DataFrame(completed)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„±ê³¼ ì§€í‘œ ê³„ì‚° (FIFO ê²°ê³¼ ê¸°ì¤€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_performance(completed_df: pd.DataFrame) -> Dict:
    """
    ë°˜í™˜:
      - num_completed_trades: ì²´ê²° ì™„ë£Œ(ë§¤ë„ ê¸°ì¤€) ê±°ë˜ ìˆ˜
      - win_rate: ìŠ¹ë¥ 
      - profit_factor: ì´ìµí•© / ì†ì‹¤í•©(ì ˆëŒ“ê°’) (ì†ì‹¤ì´ 0ì´ë©´ inf)
      - last_trade_id: ë§ˆì§€ë§‰ ë§¤ë„ íŠ¸ëœì­ì…˜ ID
      - total_pnl: ì „ì²´ ì‹¤í˜„ì†ìµ í•©ê³„
    """
    if completed_df.empty:
        return {}

    trade_pnl = completed_df.groupby('sell_id')['profit'].sum()
    total_trades = int(len(trade_pnl))
    if total_trades == 0:
        return {}

    wins = trade_pnl[trade_pnl > 0]
    losses = trade_pnl[trade_pnl < 0]

    win_trades = int((trade_pnl > 0).sum())
    win_rate = win_trades / total_trades if total_trades > 0 else 0.0

    sum_pos = float(wins.sum()) if not wins.empty else 0.0
    sum_neg_abs = float(-losses.sum()) if not losses.empty else 0.0
    profit_factor = (sum_pos / sum_neg_abs) if sum_neg_abs > 0 else float('inf')

    metrics: Dict = {
        "num_completed_trades": total_trades,
        "win_rate": win_rate,
        "profit_factor": profit_factor,
        "last_trade_id": int(completed_df['sell_id'].max()),
        "total_pnl": float(trade_pnl.sum()),
    }

    logger.info(
        f"[ì„±ê³¼] trades={metrics['num_completed_trades']} | "
        f"win_rate={metrics['win_rate']:.2%} | "
        f"PF={metrics['profit_factor']:.2f} | "
        f"total_pnl={metrics['total_pnl']:.0f} | "
        f"last_sell_id={metrics['last_trade_id']}"
    )
    return metrics


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìë™ íŠœë‹ (ì„œí‚· ë¸Œë ˆì´ì»¤ í¬í•¨) + ë””ìŠ¤ì½”ë“œ ì•Œë¦¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def tune_parameters(performance_metrics: dict, last_review_info: dict) -> int:
    """
    ì„±ê³¼ ì§€í‘œì— ë”°ë¼ config.jsonì˜ ì „ëµ íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
    ì„±ê³¼ ë¶€ì§„ ì •ì˜: win_rate < 0.5 ë˜ëŠ” profit_factor < 1.5
    """
    config = load_config()
    strategy_params = config.get("strategy_params", {}) or {}

    win_rate = float(performance_metrics.get('win_rate', 0.0))
    profit_factor = float(performance_metrics.get('profit_factor', 0.0))

    config_changed = False
    is_poor_performance = (win_rate < 0.5) or (profit_factor < 1.5)
    consecutive_failures = int(last_review_info.get("consecutive_failures", 0))

    if is_poor_performance:
        consecutive_failures += 1
        logger.warning(f"ì„±ê³¼ ë¶€ì§„ ê°ì§€. ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜: {consecutive_failures}")

        if consecutive_failures >= CONSECUTIVE_FAILURES_THRESHOLD:
            msg = (
                f"ğŸš¨ **[ê²½ê³ ] {consecutive_failures}íšŒ ì—°ì†ìœ¼ë¡œ ì„±ê³¼ê°€ ë¶€ì§„í•©ë‹ˆë‹¤.**\n"
                f"ìë™ íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ì „ëµ/ë¦¬ìŠ¤í¬ ê·œì¹™ì˜ ê·¼ë³¸ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
            logger.critical(msg)
            if WEBHOOK_URL and is_valid_webhook(WEBHOOK_URL):
                send_discord_message(content=msg)
            return consecutive_failures
    else:
        consecutive_failures = 0  # ì„±ê³¼ê°€ ì¢‹ìœ¼ë©´ ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”

    # ìŠ¹ë¥  ì €í•˜ ì‹œ: ì†ì ˆ ê°•í™”(5% ê°•í™”, Floor ì ìš©)
    if win_rate < 0.5:
        original = float(strategy_params.get('stop_loss_pct', 0.05))
        new_value = max(round(original * 0.95, 4), MIN_STOP_LOSS_PCT)
        if not np.isclose(new_value, original):
            strategy_params['stop_loss_pct'] = new_value
            logger.info(f"ìŠ¹ë¥  ì €í•˜({win_rate:.2%}) -> ì†ì ˆ ê°•í™”: {original:.3f} -> {new_value:.3f}")
            config_changed = True

    # ì†ìµë¹„ ì €í•˜ ì‹œ: ìµì ˆ ìƒí–¥(5% ìƒí–¥, Ceiling ì ìš©)
    if profit_factor < 1.5:
        original = float(strategy_params.get('take_profit_pct', 0.10))
        new_value = min(round(original * 1.05, 4), MAX_TAKE_PROFIT_PCT)
        if not np.isclose(new_value, original):
            strategy_params['take_profit_pct'] = new_value
            logger.info(f"ì†ìµë¹„ ì €í•˜({profit_factor:.2f}) -> ìµì ˆ ìƒí–¥: {original:.3f} -> {new_value:.3f}")
            config_changed = True

    if config_changed:
        config['strategy_params'] = strategy_params
        with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logger.info(f"ì „ëµ íŒŒë¼ë¯¸í„°ê°€ ìˆ˜ì •ë˜ì–´ '{CONFIG_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. {strategy_params}")

        if WEBHOOK_URL and is_valid_webhook(WEBHOOK_URL):
            summary = (
                f"[Reviewer] ìë™ íŠœë‹ ì ìš©\n"
                f"- win_rate: {win_rate:.2%}, PF: {profit_factor:.2f}\n"
                f"- stop_loss_pct: {strategy_params.get('stop_loss_pct')}\n"
                f"- take_profit_pct: {strategy_params.get('take_profit_pct')}"
            )
            send_discord_message(content=summary)

    return consecutive_failures


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CSV ë‚´ë³´ë‚´ê¸° (ê°€ëŠ¥í•œ í•„ë“œ ìµœëŒ€í•œ ì±„ì›€: GPT ì ìˆ˜ë„ ì¶”ì¶œ ì‹œë„)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _safe_get_gpt_scores(gpt_json) -> Dict:
    out = {"FinScore": None, "TechScore": None, "SectorScore": None}
    try:
        data = json.loads(str(gpt_json))
        stock_info = data.get('stock_info', {})
        out["FinScore"] = stock_info.get('FinScore', data.get('FinScore'))
        out["TechScore"] = stock_info.get('TechScore', data.get('TechScore'))
        out["SectorScore"] = stock_info.get('SectorScore', data.get('SectorScore'))
    except Exception:
        pass
    return out


def build_completed_trades_detail(raw_df: pd.DataFrame, fifo_df: pd.DataFrame) -> pd.DataFrame:
    """
    raw_df: fetch_new_tradesë¡œ ì½ì€ ì›ë³¸ ê±°ë˜
    fifo_df: match_trades_fifo ê²°ê³¼(ë§¤ë„ë³„ ë§¤ì¹­ ì¡°ê°)
    ë°˜í™˜: ë§¤ë„ê±´(sell_id) ë‹¨ìœ„ì˜ ìš”ì•½ ë ˆì½”ë“œ ì§‘í•©(ê°€ëŠ¥í•œ í•„ë“œ ì±„ì›€)
    """
    if fifo_df.empty:
        return pd.DataFrame()

    # sell_id ë‹¨ìœ„ ì§‘ê³„
    groups = []
    for sell_id, g in fifo_df.groupby('sell_id'):
        # sell í–‰(ì›ë³¸ DFì—ì„œ)
        sell_rows = raw_df[raw_df['id'] == sell_id]
        if sell_rows.empty:
            # sell ë ˆì½”ë“œê°€ ì•ˆ ë³´ì´ë©´ ìŠ¤í‚µ
            continue
        sell = sell_rows.iloc[0]

        # ë§¤ì¹­ëœ buyë“¤ì˜ ê°€ì¤‘ í‰ê·  ë§¤ì…ê°€, ìµœì´ˆ buy ì‹œê°
        total_qty = float(g['buy_qty'].sum()) if 'buy_qty' in g.columns else float(sell.get('qty', 0))
        if total_qty <= 0:
            total_qty = float(sell.get('qty', 0))

        if total_qty > 0 and 'buy_price' in g.columns and 'buy_qty' in g.columns:
            avg_buy_price = float((g['buy_price'] * g['buy_qty']).sum() / g['buy_qty'].sum())
        else:
            avg_buy_price = float('nan')

        first_buy_t = pd.to_datetime(g['buy_t'].min()) if 'buy_t' in g.columns else None
        sell_t = pd.to_datetime(sell['timestamp'])
        holding_days = (sell_t - first_buy_t).days if (first_buy_t is not None and pd.notna(first_buy_t)) else None

        # ì‹¤í˜„ì†ìµ í•©ê³„(í•´ë‹¹ sell_id)
        pnl_amount = float(g['profit'].sum())
        sell_qty = float(sell.get('qty', np.nan))
        sell_price = float(sell.get('price', np.nan))
        denom = (avg_buy_price * sell_qty) if (sell_qty and avg_buy_price and not np.isnan(avg_buy_price)) else np.nan
        pnl_rate_pct = (pnl_amount / denom) * 100 if denom and denom != 0 and not np.isnan(denom) else np.nan

        # GPT ì ìˆ˜ ì¶”ì¶œ(ê°€ëŠ¥ ì‹œ)
        gpt_score = float('nan')
        fin = tech = sector = None
        try:
            # ë§¤ì¹­ëœ buy ì¤‘ gpt_score/gpt_analysisê°€ ìˆëŠ” ì²« í•­ëª© ì‚¬ìš©
            cand = g.dropna(subset=['buy_gpt_analysis']) if 'buy_gpt_analysis' in g.columns else pd.DataFrame()
            if not cand.empty:
                scores = _safe_get_gpt_scores(cand.iloc[0]['buy_gpt_analysis'])
                fin, tech, sector = scores["FinScore"], scores["TechScore"], scores["SectorScore"]
            if 'buy_gpt_score' in g.columns and pd.notna(g['buy_gpt_score']).any():
                gpt_score = float(g['buy_gpt_score'].dropna().iloc[0])
        except Exception:
            pass

        groups.append({
            'sell_id': int(sell_id),
            'ticker': str(sell.get('ticker', '')),
            'name': str(sell.get('name', '')) if 'name' in sell else '',
            'buy_timestamp': first_buy_t,
            'sell_timestamp': sell_t,
            'holding_days': int(holding_days) if holding_days is not None else None,
            'buy_price': float(round(avg_buy_price, 4)) if not np.isnan(avg_buy_price) else None,
            'sell_price': float(round(sell_price, 4)) if not np.isnan(sell_price) else None,
            'sell_qty': float(round(sell_qty, 4)) if not np.isnan(sell_qty) else None,
            'pnl_amount': float(round(pnl_amount, 4)),
            'pnl_rate_pct': float(round(pnl_rate_pct, 4)) if not (pnl_rate_pct is None or np.isnan(pnl_rate_pct)) else None,
            'sell_reason': str(sell.get('sell_reason', '')) if 'sell_reason' in sell else '',
            'buy_strategy': str(sell.get('strategy_name', '')) if 'strategy_name' in sell else '',
            'gpt_score': float(round(gpt_score, 4)) if not (gpt_score is None or np.isnan(gpt_score)) else None,
            'FinScore': fin,
            'TechScore': tech,
            'SectorScore': sector,
        })

    if not groups:
        return pd.DataFrame()

    out = pd.DataFrame(groups).sort_values('sell_timestamp')
    return out


def export_analysis_to_csv(detail_df: pd.DataFrame):
    """ë¶„ì„ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if detail_df is None or detail_df.empty:
        logger.info("CSV ë‚´ë³´ë‚´ê¸°: ì €ì¥í•  ì™„ë£Œ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì €ì¥ ì»¬ëŸ¼ ìš°ì„ ìˆœìœ„
    final_cols = [
        'sell_id', 'ticker', 'name',
        'buy_timestamp', 'sell_timestamp', 'holding_days',
        'buy_price', 'sell_price', 'sell_qty',
        'pnl_amount', 'pnl_rate_pct',
        'sell_reason', 'buy_strategy',
        'gpt_score', 'FinScore', 'TechScore', 'SectorScore'
    ]
    use_cols = [c for c in final_cols if c in detail_df.columns]
    df_final = detail_df[use_cols].copy()

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    df_final.to_csv(ANALYSIS_CSV_PATH, index=False, encoding='utf-8-sig')
    logger.info(f"âœ… ë¶„ì„ ë¦¬í¬íŠ¸({len(df_final)}ê±´)ë¥¼ '{ANALYSIS_CSV_PATH}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# íŒŒì´í”„ë¼ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_reviewer(min_trades_for_review: int = 5, export_csv: bool = False):
    """
    ì„±ê³¼ ë¶„ì„ ë° íŠœë‹ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    - ìµœê·¼ ë¯¸ê²€í†  ê±°ë˜ë¥¼ ì½ê³ , FIFOë¡œ ì²´ê²° ìŒì„ ë§¤ì¹­
    - ìµœì†Œ Nê±´ ì´ìƒì´ë©´ ì„±ê³¼ ê³„ì‚° ë° ìë™ íŠœë‹
    - ë¦¬ë·° ë¡œê·¸(last_trade_id, consecutive_failures) ê°±ì‹ 
    - ì˜µì…˜ì— ë”°ë¼ CSV ì €ì¥
    """
    logger.info("=" * 60)
    logger.info("â–¶ ë§¤ë§¤ ì„±ê³¼ ë¶„ì„(Reviewer)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    last_info = get_last_review_info()
    last_id = int(last_info.get('last_trade_id', 0))
    logger.info(f"ë§ˆì§€ë§‰ ë¦¬ë·° ID: {last_id}")

    raw = fetch_new_trades(last_id)
    if raw.empty:
        logger.info("ìƒˆë¡œìš´ ê±°ë˜ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ìµœì†Œ ê±°ë˜ ìˆ˜(ì „ì²´ raw ê¸°ì¤€) ì²´í¬: ë„ˆë¬´ ì ìœ¼ë©´ íŠœë‹/CSV ë¯¸ìˆ˜í–‰
    if len(raw) < 2:
        logger.info("ìƒˆë¡œìš´ ê±°ë˜ ê¸°ë¡ì´ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        update_review_log(int(raw['id'].max()), int(last_info.get("consecutive_failures", 0)))
        return

    fifo = match_trades_fifo(raw)

    if fifo.empty:
        logger.info("ì™„ë£Œëœ(ë§¤ìˆ˜-ë§¤ë„ ë§¤ì¹­ëœ) ê±°ë˜ê°€ ì—†ì–´ íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        update_review_log(int(raw['id'].max()), int(last_info.get("consecutive_failures", 0)))
        return

    # ë§¤ë„ê±´(ë…ë¦½ sell_id) ê¸°ì¤€ìœ¼ë¡œ ìµœì†Œ ë¶„ì„ê±´ ì²´í¬
    completed_sells = int(fifo['sell_id'].nunique())
    if completed_sells < int(min_trades_for_review):
        logger.info(
            f"ì™„ë£Œëœ ê±°ë˜ê°€ {completed_sells}ê±´ìœ¼ë¡œ, ë¶„ì„ ìµœì†Œ ê¸°ì¤€({min_trades_for_review}ê±´)ì— ë¯¸ë‹¬. íŠœë‹/CSV ê±´ë„ˆëœ€."
        )
        update_review_log(int(raw['id'].max()), int(last_info.get("consecutive_failures", 0)))
        return

    # ì„±ê³¼ ê³„ì‚°
    metrics = analyze_performance(fifo)
    if metrics:
        consecutive_failures = tune_parameters(metrics, last_info)
        update_review_log(metrics['last_trade_id'], consecutive_failures)
        logger.info("âœ… ì„±ê³¼ ë¶„ì„ ë° ìë™ íŠœë‹ ì™„ë£Œ.")
    else:
        logger.info("ì„±ê³¼ ì§€í‘œ ìƒì„± ì‹¤íŒ¨. íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        update_review_log(int(raw['id'].max()), int(last_info.get("consecutive_failures", 0)))

    # CSV ì €ì¥ ì˜µì…˜
    if export_csv:
        detail = build_completed_trades_detail(raw, fifo)
        export_analysis_to_csv(detail)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Trading Performance Reviewer (FIFO Matching + Auto Tuner + CSV)")
    parser.add_argument(
        "--min-trades",
        type=int,
        default=5,
        help="ìë™ íŠœë‹ ë° CSV ì €ì¥ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ìµœì†Œ 'ì™„ë£Œ(ë§¤ë„)' ê±°ë˜ ìˆ˜ (ê¸°ë³¸ê°’: 5)"
    )
    parser.add_argument(
        "--export-csv",
        action="store_true",
        help="ë¶„ì„ ê²°ê³¼ë¥¼ completed_trades_analysis.csv íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
    )
    args = parser.parse_args()

    run_reviewer(min_trades_for_review=args.min_trades, export_csv=args.export_csv)
