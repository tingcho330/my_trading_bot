# src/recorder.py
import os
import sqlite3
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Set, Optional
from contextlib import contextmanager

# â”€â”€ ê³µí†µ ìœ í‹¸ â”€â”€
from utils import setup_logging, OUTPUT_DIR, KST

# â”€â”€ ë””ìŠ¤ì½”ë“œ ë…¸í‹°íŒŒì´ì–´ â”€â”€
from notifier import (
    DiscordLogHandler,
    WEBHOOK_URL,
    is_valid_webhook,
    send_discord_message,
    create_trade_embed,  # ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œê¹…/ê²½ë¡œ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
setup_logging()
logger = logging.getLogger("recorder")

# ë£¨íŠ¸ ë¡œê±°ì— ë””ìŠ¤ì½”ë“œ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì¥ì°©(ì¤‘ë³µ ë°©ì§€)
_root = logging.getLogger()
if WEBHOOK_URL and is_valid_webhook(WEBHOOK_URL):
    if not any(isinstance(h, DiscordLogHandler) for h in _root.handlers):
        _root.addHandler(DiscordLogHandler(WEBHOOK_URL))
        logger.info("DiscordLogHandler attached to root logger.")
else:
    logger.warning("ìœ íš¨í•œ DISCORD_WEBHOOK_URLì´ ì—†ì–´ ì—ëŸ¬ ë¡œê·¸ì˜ ë””ìŠ¤ì½”ë“œ ì „ì†¡ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì•Œë¦¼ ì¿¨ë‹¤ìš´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_last_sent: Dict[str, float] = {}
def _notify(msg: str, key: str, cooldown_sec: int = 120):
    if not (WEBHOOK_URL and is_valid_webhook(WEBHOOK_URL)):
        return
    now = time.time()
    if key not in _last_sent or now - _last_sent[key] >= cooldown_sec:
        _last_sent[key] = now
        try:
            send_discord_message(content=msg)
        except Exception:
            # ì•Œë¦¼ ì‹¤íŒ¨ëŠ” ê¸°ëŠ¥ì— ì˜í–¥ ì—†ë„ë¡ ë¬´ì‹œ
            pass

def _notify_embed_safe(embed: Dict, key: str, cooldown_sec: int = 120):
    if not (WEBHOOK_URL and is_valid_webhook(WEBHOOK_URL)):
        return
    now = time.time()
    if key not in _last_sent or now - _last_sent[key] >= cooldown_sec:
        _last_sent[key] = now
        try:
            send_discord_message(embeds=[embed])
        except Exception:
            pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH = str((OUTPUT_DIR / "trading_log.db").resolve())
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

# --------------------------------------------------------------------
@contextmanager
def get_db_connection(db_path: Optional[str] = None):
    """
    ì•ˆì „í•œ DB ì»¤ë„¥ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €.
    ìë™ commit/rollback/close.
    """
    final_db_path = db_path or DB_PATH
    conn = None
    try:
        conn = sqlite3.connect(final_db_path, timeout=10)
        conn.row_factory = sqlite3.Row
        logger.debug(f"DB Connection â†— {final_db_path}")
        yield conn
    except sqlite3.Error as e:
        logger.error(f"DB íŠ¸ëœì­ì…˜ ì‹¤íŒ¨: {e}", exc_info=True)
        if conn:
            conn.rollback()
        # ì‹¬ê° ì˜¤ë¥˜ ì•Œë¦¼(ì¿¨ë‹¤ìš´)
        _notify(f"ğŸ§¨ DB íŠ¸ëœì­ì…˜ ì‹¤íŒ¨: {str(e)[:900]}", key="recorder_db_tx_fail", cooldown_sec=300)
        raise
    finally:
        if conn:
            conn.close()
            logger.debug(f"DB Connection â†˜ {final_db_path}")

# --------------------------------------------------------------------
def _get_existing_columns(cursor: sqlite3.Cursor, table_name: str) -> Set[str]:
    """í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª… ì§‘í•© ë°˜í™˜"""
    cursor.execute(f"PRAGMA table_info({table_name})")
    return {row[1] for row in cursor.fetchall()}

# --------------------------------------------------------------------
def _migrate_db_schema(conn: sqlite3.Connection):
    """
    â‘  trades í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
    â‘¡ í•„ìˆ˜ ì»¬ëŸ¼ì´ ë¹ ì ¸ ìˆìœ¼ë©´ ALTER TABLE ë¡œ ì¶”ê°€
    """
    cursor = conn.cursor()

    # 1) í…Œì´ë¸” ìµœì´ˆ ìƒì„± (í•„ìš” ì‹œ)
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS trades (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp       TEXT NOT NULL,
            side            TEXT NOT NULL,
            ticker          TEXT NOT NULL,
            name            TEXT,
            qty             INTEGER NOT NULL,
            price           REAL NOT NULL,
            pnl_amount      REAL,
            parent_trade_id INTEGER,
            strategy_name   TEXT,
            trade_status    TEXT,
            strategy_details TEXT,
            gpt_summary     TEXT,
            gpt_analysis    TEXT
        )
        """
    )

    # 2) ì»¬ëŸ¼ ëˆ„ë½ ì‹œ ì¶”ê°€ (ê°œì„ ëœ ë¶€ë¶„)
    REQUIRED_COLS = {
        "trades": {
            "gpt_summary": "TEXT",
            "gpt_analysis": "TEXT",
            "strategy_details": "TEXT",
            "trade_status": "TEXT",
            "pnl_amount": "REAL",
            "gpt_score": "REAL", # GPT ì ìˆ˜
            "sell_reason": "TEXT"  # ë§¤ë„ ì‚¬ìœ 
        }
    }

    for tbl, col_map in REQUIRED_COLS.items():
        existing = _get_existing_columns(cursor, tbl)
        for col, coltype in col_map.items():
            if col not in existing:
                logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜: {tbl}.{col} ì»¬ëŸ¼ ì¶”ê°€")
                cursor.execute(f"ALTER TABLE {tbl} ADD COLUMN {col} {coltype}")

    conn.commit()

# --------------------------------------------------------------------
def initialize_db(db_path: Optional[str] = None):
    """DB ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ê²€ì¦/ë§ˆì´ê·¸ë ˆì´ì…˜"""
    try:
        with get_db_connection(db_path) as conn:
            _migrate_db_schema(conn)
        logger.info("âœ… DB ìŠ¤í‚¤ë§ˆ í™•ì¸ & ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    except Exception as e:
        logger.critical(f"DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        _notify(f"ğŸ§¨ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)[:900]}", key="recorder_db_init_fail", cooldown_sec=600)
        raise

# --------------------------------------------------------------------
# ë°ì´í„° ê¸°ë¡ ë° ì¡°íšŒ
# --------------------------------------------------------------------
def record_trade(trade_data: dict, db_path: Optional[str] = None):
    """ê±°ë˜ ë°ì´í„°ë¥¼ trades í…Œì´ë¸”ì— INSERT"""
    if not trade_data:
        return

    gpt_analysis_data = trade_data.get("gpt_analysis")
    gpt_analysis_json = (
        json.dumps(gpt_analysis_data, ensure_ascii=False)
        if isinstance(gpt_analysis_data, dict)
        else gpt_analysis_data
    )
    
    # --- ê°œì„ ëœ ë¶€ë¶„ ---
    # gpt_analysisì—ì„œ score ì¶”ì¶œ
    gpt_score = None
    if isinstance(gpt_analysis_data, dict):
        # 'stock_info' ì•ˆì— 'Score'ê°€ ìˆì„ ìˆ˜ ìˆìŒ
        stock_info = gpt_analysis_data.get("stock_info", {})
        if "Score" in stock_info:
            gpt_score = stock_info.get("Score")
        # ë˜ëŠ” gpt_analysis ìµœìƒìœ„ì— ìˆì„ ìˆ˜ë„ ìˆìŒ
        elif "Overall Score" in gpt_analysis_data:
            gpt_score = gpt_analysis_data.get("Overall Score")

    sql = """
        INSERT INTO trades (
            timestamp, side, ticker, name, qty, price,
            pnl_amount, parent_trade_id, strategy_name, trade_status,
            strategy_details, gpt_summary, gpt_analysis,
            gpt_score, sell_reason
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
    """

    ts = datetime.now(KST).isoformat()
    params = (
        ts,
        trade_data.get("side"),
        trade_data.get("ticker"),
        trade_data.get("name"),
        int(trade_data.get("qty", 0)),
        float(trade_data.get("price", 0.0)),
        trade_data.get("pnl_amount"),
        trade_data.get("parent_trade_id"),
        trade_data.get("strategy_name"),
        trade_data.get("trade_status"),
        json.dumps(trade_data.get("strategy_details"), ensure_ascii=False)
        if trade_data.get("strategy_details")
        else None,
        trade_data.get("gpt_summary"),
        gpt_analysis_json,
        gpt_score, # gpt_score ì¶”ê°€
        trade_data.get("sell_reason") # sell_reason ì¶”ê°€
    )
    # --- ì—¬ê¸°ê¹Œì§€ ---

    try:
        with get_db_connection(db_path) as conn:
            conn.execute(sql, params)
            conn.commit()
        # ë¡œê·¸ & (ì„ íƒ) ê°„ë‹¨ ì•Œë¦¼
        s = trade_data.get("side", "").upper()
        name = trade_data.get("name")
        qty = trade_data.get("qty")
        logger.info(f"âœ… ê±°ë˜ ê¸°ë¡: {s} {name} {qty}ì£¼ (ts={ts})")

        # ì„ë² ë“œ ì•Œë¦¼(ìˆìœ¼ë©´)
        try:
            embed = create_trade_embed({
                "side": s,
                "name": name,
                "ticker": trade_data.get("ticker"),
                "qty": trade_data.get("qty"),
                "price": trade_data.get("price"),
                "trade_status": trade_data.get("trade_status"),
                "strategy_details": trade_data.get("strategy_details"),
            })
            _notify_embed_safe(embed, key=f"recorder_insert_{s}_{trade_data.get('ticker','')}", cooldown_sec=60)
        except Exception:
            # create_trade_embed ë¯¸ì¡´ì¬ ë˜ëŠ” ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ë¡œ ìµœì†Œ ì•Œë¦¼(ì¿¨ë‹¤ìš´)
            _notify(
                f"ğŸ“ ê±°ë˜ ê¸°ë¡: {s} {name} x{qty} @ {trade_data.get('price')}",
                key=f"recorder_insert_text_{trade_data.get('ticker','')}",
                cooldown_sec=60
            )

    except Exception as e:
        logger.error(f"DB ê±°ë˜ ê¸°ë¡ ì‹¤íŒ¨: {e}", exc_info=True)
        _notify(f"ğŸ§¨ DB ê±°ë˜ ê¸°ë¡ ì‹¤íŒ¨: {str(e)[:900]}", key="recorder_record_fail", cooldown_sec=300)

def fetch_active_trades(db_path: Optional[str] = None) -> List[Dict]:
    """trade_status='active' ì¸ ê±°ë˜ ë°˜í™˜"""
    active_trades = []
    try:
        with get_db_connection(db_path) as conn:
            rows = conn.execute(
                "SELECT * FROM trades WHERE trade_status = 'active'"
            ).fetchall()
            for row in rows:
                trade = dict(row)
                if trade.get("strategy_details"):
                    try:
                        trade["strategy_details"] = json.loads(trade["strategy_details"])
                    except Exception:
                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ìœ ì§€
                        pass
                active_trades.append(trade)
    except Exception as e:
        logger.error(f"Active ê±°ë˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        _notify(f"ğŸ§¨ Active ê±°ë˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:900]}", key="recorder_fetch_active_fail", cooldown_sec=300)
    return active_trades

def update_trade_status(
    trade_id: int,
    new_status: str,
    new_details: Dict = None,
    db_path: Optional[str] = None,
):
    """ê±°ë˜ ìƒíƒœ(ì˜ˆ: activeâ†’completed) ì—…ë°ì´íŠ¸"""
    details_json = json.dumps(new_details, ensure_ascii=False) if new_details else None
    sql = "UPDATE trades SET trade_status = ?, strategy_details = ? WHERE id = ?"
    try:
        with get_db_connection(db_path) as conn:
            conn.execute(sql, (new_status, details_json, trade_id))
            conn.commit()
        logger.info(f"ê±°ë˜ ID {trade_id} â†’ ìƒíƒœ '{new_status}' ì—…ë°ì´íŠ¸")

        # ê°„ë‹¨ ì•Œë¦¼(ìƒíƒœ ë³€ê²½ ì¤‘ìš” ì´ë²¤íŠ¸)
        _notify(f"ğŸ”„ ê±°ë˜ ìƒíƒœ ë³€ê²½: id={trade_id}, status={new_status}",
                key=f"recorder_status_{trade_id}_{new_status}", cooldown_sec=120)

    except Exception as e:
        logger.error(f"ê±°ë˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ID={trade_id}): {e}")
        _notify(f"ğŸ§¨ ê±°ë˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ID={trade_id}): {str(e)[:900]}",
                key="recorder_update_status_fail", cooldown_sec=300)

def fetch_trades_by_tickers(
    tickers: List[str], db_path: Optional[str] = None
) -> Dict[str, Dict]:
    """í‹°ì»¤ë³„ ë§ˆì§€ë§‰ ë§¤ìˆ˜ ê±°ë˜ ì •ë³´ë¥¼ dict ë¡œ ë°˜í™˜"""
    if not tickers:
        return {}

    trades_map = {}
    placeholders = ",".join("?" for _ in tickers)
    query = f"""
        SELECT * FROM trades
        WHERE id IN (
            SELECT MAX(id) FROM trades
            WHERE side = 'buy' AND ticker IN ({placeholders})
            GROUP BY ticker
        )
    """
    try:
        with get_db_connection(db_path) as conn:
            rows = conn.execute(query, tickers).fetchall()
            for row in rows:
                trades_map[row["ticker"]] = dict(row)
    except Exception as e:
        logger.error(f"í‹°ì»¤ë³„ ê±°ë˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        _notify(f"ğŸ§¨ í‹°ì»¤ë³„ ê±°ë˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:900]}", key="recorder_fetch_tickers_fail", cooldown_sec=300)

    return trades_map

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == '__main__':
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (í…Œì´ë¸” ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜)
    initialize_db()

    # --- í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ---
    sample_buy_trade = {
        "side": "buy",
        "ticker": "005930",
        "name": "ì‚¼ì„±ì „ì",
        "qty": 10,
        "price": 70000,
        "strategy_name": "TrendFollowingStrategy",
        "trade_status": "active",
        "gpt_summary": "ê°•ë ¥í•œ ê¸°ìˆ ì  ì§€í‘œì™€ ê¸ì •ì ì¸ ë‰´ìŠ¤ íë¦„ì— ê¸°ë°˜í•œ ë§¤ìˆ˜ ê²°ì •",
        "gpt_analysis": {
            "Overall Score": 0.85,
            "FinScore": 0.7,
            "TechScore": 0.9,
            "NewsSentiment": "positive"
        }
    }

    sample_sell_trade = {
        "side": "sell",
        "ticker": "000660",
        "name": "SKí•˜ì´ë‹‰ìŠ¤",
        "qty": 5,
        "price": 150000,
        "pnl_amount": 50000,  # 5ë§Œì› ìˆ˜ìµ
        "parent_trade_id": 1,  # ë§¤ìˆ˜ ê±°ë˜ ID
        "strategy_name": "RsiReversalStrategy",
        "trade_status": "completed",
        "strategy_details": {"RSI": 75, "reason": "RSI ê³¼ë§¤ìˆ˜ êµ¬ê°„ ì§„ì…"},
        "sell_reason": "RSI ê³¼ë§¤ìˆ˜ êµ¬ê°„ ì§„ì…"
    }

    # 1. ë§¤ìˆ˜ ê¸°ë¡ í…ŒìŠ¤íŠ¸
    record_trade(sample_buy_trade)

    # 2. í˜„ì¬ active ìƒíƒœì¸ ê±°ë˜ ì¡°íšŒ
    print("\n--- Active Trades ---")
    active = fetch_active_trades()
    print(json.dumps(active, indent=2, ensure_ascii=False))

    # 3. ë§¤ë„ ê¸°ë¡ í…ŒìŠ¤íŠ¸
    record_trade(sample_sell_trade)

    # 4. í‹°ì»¤ë¡œ ê±°ë˜ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("\n--- Fetch by Tickers ---")
    trades = fetch_trades_by_tickers(["005930"])
    print(json.dumps(trades, indent=2, ensure_ascii=False))

    # 5. ê±°ë˜ ìƒíƒœ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
    if active:
        update_trade_status(active[0]['id'], "completed")
        print("\n--- Active Trades After Update ---")
        active_after_update = fetch_active_trades()
        print(json.dumps(active_after_update, indent=2, ensure_ascii=False))